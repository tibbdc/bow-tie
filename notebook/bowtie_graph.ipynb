{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import cobra \n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../code/')\n",
    "from path_analysis_function import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input and output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs_of_currency_metabolites_file = \"../data/external/pairs_of_currency_metabolites.csv\" #the file stores the currency metabolite pairs\n",
    "special_currency_metabolites_file = \"../data/external/special_currency_metabolites.csv\" #the file stores the special currency metabolites\n",
    "modelfile = '../data/external/model/'   #folder containing the models\n",
    "interim_save_path = '../data/interim/bowtie_graph/' #folder containing intermediate results\n",
    "result_save_path = '../data/result/bowtie_graph/' # Bowtie result folders for different models\n",
    "biggid2name=pd.read_csv(\"../data/external/biggid2name.csv\",index_col=0)#All metabolite ID and Name of BIGG\n",
    "bowtie_graph_outputfile = result_save_path+'bowtie_graph_total_output.csv' # Bowtie result for different models\n",
    "bowtie_graph_analysis_tablefile = '../data/result/bowtie_graph/bowtie_graph_analysis_table.csv' #statistics table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get currency metabolite from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pairs_of_currency_metabolites = pd.read_csv(pairs_of_currency_metabolites_file)\n",
    "special_currency_metabolites = pd.read_csv(special_currency_metabolites_file)\n",
    "\n",
    "pi_pairs1 = [tuple(x.split(\",\")) for x in pairs_of_currency_metabolites['pi_pairs1'] if str(x) != 'nan']\n",
    "pi_pairs2 = [tuple(x.split(\",\")) for x in pairs_of_currency_metabolites['pi_pairs2'] if str(x) != 'nan']\n",
    "h_pairs1 = [tuple(x.split(\",\")) for x in pairs_of_currency_metabolites['h_pairs1'] if str(x) != 'nan']\n",
    "h_pairs2 = [tuple(x.split(\",\")) for x in pairs_of_currency_metabolites['h_pairs2'] if str(x) != 'nan']\n",
    "nh4_pairs = [tuple(x.split(\",\")) for x in pairs_of_currency_metabolites['nh4_pairs'] if str(x) != 'nan']\n",
    "other_pairs = [tuple(x.split(\",\")) for x in pairs_of_currency_metabolites['other_pairs'] if str(x) != 'nan']\n",
    "\n",
    "currency_mets = [x for x in special_currency_metabolites['excluded'] if str(x) != 'nan']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get bow tie structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iAF692 247 195 32\n",
      "iAF987 548 242 88\n",
      "iAM_Pb448 508 109 79\n",
      "iAM_Pc455 514 105 81\n",
      "iAM_Pf480 516 105 82\n",
      "iAM_Pk459 514 107 81\n",
      "iHN637 294 177 59\n",
      "iJN1463 933 223 594\n",
      "iML1515 906 230 411\n",
      "iPC815 615 212 233\n",
      "iSDY_1059 782 276 247\n",
      "iSF_1195 771 271 364\n",
      "iSSON_1240 810 265 383\n",
      "iSbBS512_1146 802 254 288\n",
      "iYL1228 763 201 379\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "modelfile_list = sorted(glob.glob(modelfile+'*.xml'), reverse=False)\n",
    "for use_model_file in modelfile_list:\n",
    "    model_name = use_model_file.split('/')[-1].split('.')[0]\n",
    "    if not os.path.exists(interim_save_path):\n",
    "        os.makedirs(interim_save_path)\n",
    "    #covert the model to a graph\n",
    "    resultfile=interim_save_path+ model_name+'_metabolite_links.txt'\n",
    "    model = cobra.io.read_sbml_model(use_model_file)\n",
    "    G=nx.MultiDiGraph()\n",
    "    for rea in model.reactions:\n",
    "        if not rea.boundary and 'BIOMASS' not in rea.id: \n",
    "            sub_pro = get_metpair(rea,pi_pairs1,h_pairs1,pi_pairs2,h_pairs2,nh4_pairs,other_pairs,currency_mets) \n",
    "            for sp in sub_pro:\n",
    "                G.add_edge(sp[0], sp[1], label=rea.id)\n",
    "                if rea.reversibility:  \n",
    "                    G.add_edge(sp[1], sp[0], label=rea.id)\n",
    "    nx.write_edgelist(G, resultfile) \n",
    "    \n",
    "    #calculate bowtie \n",
    "    if not os.path.exists(result_save_path):\n",
    "        os.makedirs(result_save_path)\n",
    "    btfile=result_save_path+ model_name+'_bowtie.txt'\n",
    "    bowtiefile=open(btfile,'w')\n",
    "    gsc=list(max(nx.strongly_connected_components(G), key=len)) #giant strong component,convert returned set to list\n",
    "    n=gsc[0] #select a node in GSC\n",
    "    outdm=set(nx.single_source_shortest_path_length(G,n).keys()) #output domain     #Compute the shortest path lengths from source to all reachable nodes.\n",
    "    indm=set(nx.single_source_shortest_path_length(G.reverse(),n).keys()) #input domain\n",
    "    outs=list(outdm-indm) #use sets to find intersection, union and difference between two lists\n",
    "    ins=list(indm-outdm)\n",
    "    allnodes=set(G.nodes())\n",
    "    isset=list(allnodes-(indm|outdm))\n",
    "    for node in gsc:\n",
    "        bowtiefile.write(node+'\\tGSC\\n')\n",
    "    for node in ins:\n",
    "        bowtiefile.write(node+'\\tIN\\n')\n",
    "    for node in outs:       \n",
    "        bowtiefile.write(node+'\\tOUT\\n')\n",
    "    for node in isset:\n",
    "        bowtiefile.write(node+'\\tIS\\n')\n",
    "    bowtiefile.close() \n",
    "    print(model_name,str(len(gsc)),str(len(outs)),str(len(ins)))\n",
    "print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/result/bowtie_graph/iAF692_bowtie.txt\n",
      "../data/result/bowtie_graph/iAF987_bowtie.txt\n",
      "../data/result/bowtie_graph/iAM_Pb448_bowtie.txt\n",
      "../data/result/bowtie_graph/iAM_Pc455_bowtie.txt\n",
      "../data/result/bowtie_graph/iAM_Pf480_bowtie.txt\n",
      "../data/result/bowtie_graph/iAM_Pk459_bowtie.txt\n",
      "../data/result/bowtie_graph/iHN637_bowtie.txt\n",
      "../data/result/bowtie_graph/iJN1463_bowtie.txt\n",
      "../data/result/bowtie_graph/iML1515_bowtie.txt\n",
      "../data/result/bowtie_graph/iPC815_bowtie.txt\n",
      "../data/result/bowtie_graph/iSDY_1059_bowtie.txt\n",
      "../data/result/bowtie_graph/iSF_1195_bowtie.txt\n",
      "../data/result/bowtie_graph/iSSON_1240_bowtie.txt\n",
      "../data/result/bowtie_graph/iSbBS512_1146_bowtie.txt\n",
      "../data/result/bowtie_graph/iYL1228_bowtie.txt\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "#Read the Bowtie table, extract each column of metabolites, and determine the category of metabolites in the model\n",
    "#Organize the resulting file into a Bowtie\n",
    "globfiles = sorted(glob.glob(result_save_path+'*_bowtie.txt'), reverse=False) \n",
    "#print(globfile1)\n",
    "for filename in globfiles:\n",
    "    print(filename)\n",
    "    #model_name = use_model_file.split('\\\\')[1].split('.')[0] #for windows\n",
    "    model_name = filename.split('/')[-1].split('_bowtie')[0]\n",
    "    model_bowtie = pd.read_csv(filename,names=['bowtie'],sep='\\t')\n",
    "    for index, row in model_bowtie.iterrows():   \n",
    "        if index in biggid2name.index:\n",
    "            biggid2name.loc[index,model_name]=row['bowtie']\n",
    "\n",
    "biggid2name.to_csv(bowtie_graph_outputfile, header=True, index=True,mode='w')\n",
    "print('finish')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iAF692\n",
      "iAF987\n",
      "iAM_Pb448\n",
      "iAM_Pc455\n",
      "iAM_Pf480\n",
      "iAM_Pk459\n",
      "iHN637\n",
      "iJN1463\n",
      "iML1515\n",
      "iPC815\n",
      "iSDY_1059\n",
      "iSF_1195\n",
      "iSSON_1240\n",
      "iSbBS512_1146\n",
      "iYL1228\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "modelfile_list = sorted(glob.glob(modelfile+'*.xml'), reverse=False)\n",
    "bowtie_graph_data=pd.read_csv(bowtie_graph_outputfile,index_col=0)\n",
    "bowtie_analysis_table = pd.DataFrame()\n",
    "for eachmodelfile in modelfile_list:\n",
    "    #model_name = eachmodelfile.split('\\\\')[1].split('.')[0] #for windows\n",
    "    model_name = eachmodelfile.split('/')[-1].split('.')[0]\n",
    "    print(model_name)\n",
    "    record_has_data = [x for x in bowtie_graph_data[model_name] if str(x) != 'nan']\n",
    "    bowtie_analysis_table.loc[model_name,'All Metabolites']=len(record_has_data)\n",
    "    bowtie_analysis_table.loc[model_name,'GSC']=record_has_data.count('GSC')\n",
    "    bowtie_analysis_table.loc[model_name,'IN']=record_has_data.count('IN')\n",
    "    bowtie_analysis_table.loc[model_name,'OUT']=record_has_data.count('OUT')\n",
    "    bowtie_analysis_table.loc[model_name,'IS']=record_has_data.count('IS')\n",
    "\n",
    "bowtie_analysis_table.to_csv(bowtie_graph_analysis_tablefile, header=True, index=True,mode='w')\n",
    "print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bow_tie",
   "language": "python",
   "name": "bow_tie"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
